# coding = utf-8
# !/usr/bin/python

"""

ä½œè€… ç¹å ğŸš“ å†…å®¹å‡ä»äº’è”ç½‘æ”¶é›†è€Œæ¥ ä»…ä¾›äº¤æµå­¦ä¹ ä½¿ç”¨ ç‰ˆæƒå½’åŸåˆ›è€…æ‰€æœ‰ å¦‚ä¾µçŠ¯äº†æ‚¨çš„æƒç›Š è¯·é€šçŸ¥ä½œè€… å°†åŠæ—¶åˆ é™¤ä¾µæƒå†…å®¹
                    ====================fanhua====================

"""

from Crypto.Util.Padding import unpad
from urllib.parse import unquote
from Crypto.Cipher import ARC4
from urllib.parse import quote
from base.spider import Spider
from bs4 import BeautifulSoup
import urllib.request
import urllib.parse
import binascii
import requests
import base64
import json
import time
import sys
import re
import os

sys.path.append('..')

xurl = "https://cupfoxys.cc"

headerx = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.87 Safari/537.36'
          }

# headerx = {
#     'User-Agent': 'Linux; Android 12; Pixel 3 XL) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.101 Mobile Safari/537.36'
#           }

pm = ''

class Spider(Spider):
    global xurl
    global headerx

    def getName(self):
        return "é¦–é¡µ"

    def init(self, extend):
        pass

    def isVideoFormat(self, url):
        pass

    def manualVideoCheck(self):
        pass

    def extract_middle_text(self, text, start_str, end_str, pl, start_index1: str = '', end_index2: str = ''):
        if pl == 3:
            plx = []
            while True:
                start_index = text.find(start_str)
                if start_index == -1:
                    break
                end_index = text.find(end_str, start_index + len(start_str))
                if end_index == -1:
                    break
                middle_text = text[start_index + len(start_str):end_index]
                plx.append(middle_text)
                text = text.replace(start_str + middle_text + end_str, '')
            if len(plx) > 0:
                purl = ''
                for i in range(len(plx)):
                    matches = re.findall(start_index1, plx[i])
                    output = ""
                    for match in matches:
                        match3 = re.search(r'(?:^|[^0-9])(\d+)(?:[^0-9]|$)', match[1])
                        if match3:
                            number = match3.group(1)
                        else:
                            number = 0
                        if 'http' not in match[0]:
                            output += f"#{ match[1]}${number}{xurl}{match[0]}"
                        else:
                            output += f"#{ match[1]}${number}{match[0]}"
                    output = output[1:]
                    purl = purl + output + "$$$"
                purl = purl[:-3]
                return purl
            else:
                return ""
        else:
            start_index = text.find(start_str)
            if start_index == -1:
                return ""
            end_index = text.find(end_str, start_index + len(start_str))
            if end_index == -1:
                return ""

        if pl == 0:
            middle_text = text[start_index + len(start_str):end_index]
            return middle_text.replace("\\", "")

        if pl == 1:
            middle_text = text[start_index + len(start_str):end_index]
            matches = re.findall(start_index1, middle_text)
            if matches:
                jg = ' '.join(matches)
                return jg

        if pl == 2:
            middle_text = text[start_index + len(start_str):end_index]
            matches = re.findall(start_index1, middle_text)
            if matches:
                new_list = [f'{item}' for item in matches]
                jg = '$$$'.join(new_list)
                return jg

    def homeContent(self, filter):
        result = {}
        result ={"class":[{"type_id":"dy","type_name":"ç”µå½±"},{"type_id":"dsj","type_name":"ç”µè§†å‰§"},{"type_id":"dm","type_name":"åŠ¨æ¼«"},{"type_id":"zy","type_name":"ç»¼è‰º"}],"list":[],"filters":{"dy":[{"key":"ç±»å‹","name":"ç±»å‹","value":[{"n":"å…¨éƒ¨","v":""},{"n":"å–œå‰§","v":"å–œå‰§"},{"n":"çˆ±æƒ…","v":"çˆ±æƒ…"},{"n":"åŠ¨ä½œ","v":"åŠ¨ä½œ"},{"n":"ç§‘å¹»","v":"ç§‘å¹»"},{"n":"å‰§æƒ…","v":"å‰§æƒ…"},{"n":"æˆ˜äº‰","v":"æˆ˜äº‰"},{"n":"è­¦åŒª","v":"è­¦åŒª"},{"n":"çŠ¯ç½ª","v":"çŠ¯ç½ª"},{"n":"åŠ¨ç”»","v":"åŠ¨ç”»"},{"n":"å¥‡å¹»","v":"å¥‡å¹»"},{"n":"æ­¦ä¾ ","v":"æ­¦ä¾ "},{"n":"å†’é™©","v":"å†’é™©"},{"n":"æªæˆ˜","v":"æªæˆ˜"},{"n":"ææ€–","v":"ææ€–"},{"n":"æ‚¬ç–‘","v":"æ‚¬ç–‘"},{"n":"æƒŠæ‚š","v":"æƒŠæ‚š"},{"n":"ç»å…¸","v":"ç»å…¸"},{"n":"é’æ˜¥","v":"é’æ˜¥"},{"n":"æ–‡è‰º","v":"æ–‡è‰º"},{"n":"å¾®ç”µå½±","v":"å¾®ç”µå½±"},{"n":"å¤è£…","v":"å¤è£…"},{"n":"å†å²","v":"å†å²"},{"n":"è¿åŠ¨","v":"è¿åŠ¨"},{"n":"å†œæ‘","v":"å†œæ‘"},{"n":"å„¿ç«¥","v":"å„¿ç«¥"},{"n":"ç½‘ç»œç”µå½±","v":"ç½‘ç»œç”µå½±"}]},{"key":"åœ°åŒº","name":"åœ°åŒº","value":[{"n":"å…¨éƒ¨","v":""},{"n":"å¤§é™†","v":"å¤§é™†"},{"n":"é¦™æ¸¯","v":"é¦™æ¸¯"},{"n":"å°æ¹¾","v":"å°æ¹¾"},{"n":"ç¾å›½","v":"ç¾å›½"},{"n":"æ³•å›½","v":"æ³•å›½"},{"n":"è‹±å›½","v":"è‹±å›½"},{"n":"æ—¥æœ¬","v":"æ—¥æœ¬"},{"n":"éŸ©å›½","v":"éŸ©å›½"},{"n":"å¾·å›½","v":"å¾·å›½"},{"n":"æ³°å›½","v":"æ³°å›½"},{"n":"å°åº¦","v":"å°åº¦"},{"n":"æ„å¤§åˆ©","v":"æ„å¤§åˆ©"},{"n":"è¥¿ç­ç‰™","v":"è¥¿ç­ç‰™"},{"n":"åŠ æ‹¿å¤§","v":"åŠ æ‹¿å¤§"},{"n":"å…¶ä»–","v":"å…¶ä»–"}]},{"key":"å¹´ä»£","name":"å¹´ä»£","value":[{"n":"å…¨éƒ¨","v":""},{"n":"2025","v":"2025"},{"n":"2024","v":"2024"},{"n":"2023","v":"2023"},{"n":"2022","v":"2022"},{"n":"2021","v":"2021"},{"n":"2020","v":"2020"},{"n":"2019","v":"2019"},{"n":"2018","v":"2018"},{"n":"2017","v":"2017"},{"n":"2016","v":"2016"},{"n":"2015","v":"2015"},{"n":"2014","v":"2014"},{"n":"2013","v":"2013"},{"n":"2012","v":"2012"},{"n":"2011","v":"2011"},{"n":"2010","v":"2010"}]},{"key":"è¯­è¨€","name":"è¯­è¨€","value":[{"n":"å…¨éƒ¨","v":""},{"n":"å›½è¯­","v":"å›½è¯­"},{"n":"è‹±è¯­","v":"è‹±è¯­"},{"n":"ç²¤è¯­","v":"ç²¤è¯­"},{"n":"é—½å—è¯­","v":"é—½å—è¯­"},{"n":"éŸ©è¯­","v":"éŸ©è¯­"},{"n":"æ—¥è¯­","v":"æ—¥è¯­"},{"n":"æ³•è¯­","v":"æ³•è¯­"},{"n":"å¾·è¯­","v":"å¾·è¯­"},{"n":"å…¶å®ƒ","v":"å…¶å®ƒ"}]}],"dsj":[{"key":"ç±»å‹","name":"ç±»å‹","value":[{"n":"å…¨éƒ¨","v":""},{"n":"çˆ±æƒ…","v":"çˆ±æƒ…"},{"n":"å¤è£…","v":"å¤è£…"},{"n":"æ‚¬ç–‘","v":"æ‚¬ç–‘"},{"n":"éƒ½å¸‚","v":"éƒ½å¸‚"},{"n":"æ­¦ä¾ ","v":"æ­¦ä¾ "},{"n":"æˆ˜äº‰","v":"æˆ˜äº‰"},{"n":"å†›æ—…","v":"å†›æ—…"},{"n":"æƒè°‹","v":"æƒè°‹"},{"n":"é’æ˜¥å¶åƒ","v":"é’æ˜¥å¶åƒ"},{"n":"å–œå‰§","v":"å–œå‰§"},{"n":"å®¶åº­","v":"å®¶åº­"},{"n":"çŠ¯ç½ª","v":"çŠ¯ç½ª"},{"n":"åŠ¨ä½œ","v":"åŠ¨ä½œ"},{"n":"ç§‘å¹»","v":"ç§‘å¹»"},{"n":"ç«æŠ€","v":"ç«æŠ€"},{"n":"ç„å¹»","v":"ç„å¹»"},{"n":"å¥‡å¹»","v":"å¥‡å¹»"},{"n":"å‰§æƒ…","v":"å‰§æƒ…"},{"n":"å†å²","v":"å†å²"},{"n":"ç»å…¸","v":"ç»å…¸"},{"n":"ä¹¡æ‘","v":"ä¹¡æ‘"},{"n":"æƒ…æ™¯","v":"æƒ…æ™¯"},{"n":"å•†æˆ˜","v":"å•†æˆ˜"},{"n":"ç½‘å‰§","v":"ç½‘å‰§"},{"n":"å…¶ä»–","v":"å…¶ä»–"}]},{"key":"åœ°åŒº","name":"åœ°åŒº","value":[{"n":"å…¨éƒ¨","v":""},{"n":"å¤§é™†","v":"å¤§é™†"},{"n":"éŸ©å›½","v":"éŸ©å›½"},{"n":"é¦™æ¸¯","v":"é¦™æ¸¯"},{"n":"å°æ¹¾","v":"å°æ¹¾"},{"n":"æ—¥æœ¬","v":"æ—¥æœ¬"},{"n":"ç¾å›½","v":"ç¾å›½"},{"n":"æ³°å›½","v":"æ³°å›½"},{"n":"è‹±å›½","v":"è‹±å›½"},{"n":"æ–°åŠ å¡","v":"æ–°åŠ å¡"},{"n":"å…¶ä»–","v":"å…¶ä»–"}]},{"key":"å¹´ä»£","name":"å¹´ä»£","value":[{"n":"å…¨éƒ¨","v":""},{"n":"2025","v":"2025"},{"n":"2024","v":"2024"},{"n":"2023","v":"2023"},{"n":"2022","v":"2022"},{"n":"2021","v":"2021"},{"n":"2020","v":"2020"},{"n":"2019","v":"2019"},{"n":"2018","v":"2018"},{"n":"2017","v":"2017"},{"n":"2016","v":"2016"},{"n":"2015","v":"2015"},{"n":"2014","v":"2014"},{"n":"2013","v":"2013"},{"n":"2012","v":"2012"},{"n":"2011","v":"2011"},{"n":"2010","v":"2010"},{"n":"2009","v":"2009"},{"n":"2008","v":"2008"},{"n":"2006","v":"2006"},{"n":"2005","v":"2005"},{"n":"2004","v":"2004"}]},{"key":"è¯­è¨€","name":"è¯­è¨€","value":[{"n":"å…¨éƒ¨","v":""},{"n":"å›½è¯­","v":"å›½è¯­"},{"n":"è‹±è¯­","v":"è‹±è¯­"},{"n":"ç²¤è¯­","v":"ç²¤è¯­"},{"n":"é—½å—è¯­","v":"é—½å—è¯­"},{"n":"éŸ©è¯­","v":"éŸ©è¯­"},{"n":"æ—¥è¯­","v":"æ—¥è¯­"},{"n":"å…¶å®ƒ","v":"å…¶å®ƒ"}]}],"dm":[{"key":"ç±»å‹","name":"ç±»å‹","value":[{"n":"å…¨éƒ¨","v":""},{"n":"æ­¦ä¾ ","v":"æ­¦ä¾ "},{"n":"æˆ˜æ–—","v":"æˆ˜æ–—"},{"n":"æƒ…æ„Ÿ","v":"æƒ…æ„Ÿ"},{"n":"ç§‘å¹»","v":"ç§‘å¹»"},{"n":"çƒ­è¡€","v":"çƒ­è¡€"},{"n":"ç„å¹»","v":"ç„å¹»"},{"n":"æ¨ç†","v":"æ¨ç†"},{"n":"é­”å¹»","v":"é­”å¹»"},{"n":"æç¬‘","v":"æç¬‘"},{"n":"å†’é™©","v":"å†’é™©"},{"n":"èè‰","v":"èè‰"},{"n":"æ ¡å›­","v":"æ ¡å›­"},{"n":"æ‹çˆ±","v":"æ‹çˆ±"},{"n":"æ‚¬ç–‘","v":"æ‚¬ç–‘"},{"n":"æ—¥å¸¸","v":"æ—¥å¸¸"},{"n":"çœŸäºº","v":"çœŸäºº"},{"n":"å†å²","v":"å†å²"},{"n":"ç»å…¸","v":"ç»å…¸"},{"n":"åŠ¨ä½œ","v":"åŠ¨ä½œ"},{"n":"æœºæˆ˜","v":"æœºæˆ˜"},{"n":"ç«æŠ€","v":"ç«æŠ€"},{"n":"è¿åŠ¨","v":"è¿åŠ¨"},{"n":"æˆ˜äº‰","v":"æˆ˜äº‰"},{"n":"å°‘å¹´","v":"å°‘å¹´"},{"n":"å°‘å¥³","v":"å°‘å¥³"},{"n":"ç¤¾ä¼š","v":"ç¤¾ä¼š"},{"n":"åŸåˆ›","v":"åŸåˆ›"},{"n":"äº²å­","v":"äº²å­"},{"n":"ç›Šæ™º","v":"ç›Šæ™º"},{"n":"åŠ±å¿—","v":"åŠ±å¿—"},{"n":"å…¶ä»–","v":"å…¶ä»–"}]},{"key":"åœ°åŒº","name":"åœ°åŒº","value":[{"n":"å…¨éƒ¨","v":""},{"n":"å¤§é™†","v":"å¤§é™†"},{"n":"æ—¥æœ¬","v":"æ—¥æœ¬"},{"n":"ç¾å›½","v":"ç¾å›½"},{"n":"å…¶ä»–","v":"å…¶ä»–"}]},{"key":"å¹´ä»£","name":"å¹´ä»£","value":[{"n":"å…¨éƒ¨","v":""},{"n":"2025","v":"2025"},{"n":"2024","v":"2024"},{"n":"2023","v":"2023"},{"n":"2022","v":"2022"},{"n":"2021","v":"2021"},{"n":"2020","v":"2020"},{"n":"2019","v":"2019"},{"n":"2018","v":"2018"},{"n":"2017","v":"2017"},{"n":"2016","v":"2016"},{"n":"2015","v":"2015"},{"n":"2014","v":"2014"},{"n":"2013","v":"2013"},{"n":"2012","v":"2012"},{"n":"2011","v":"2011"},{"n":"2010","v":"2010"},{"n":"2009","v":"2009"},{"n":"2008","v":"2008"},{"n":"2007","v":"2007"},{"n":"2006","v":"2006"},{"n":"2005","v":"2005"},{"n":"2004","v":"2004"}]},{"key":"è¯­è¨€","name":"è¯­è¨€","value":[{"n":"å…¨éƒ¨","v":""},{"n":"å›½è¯­","v":"å›½è¯­"},{"n":"è‹±è¯­","v":"è‹±è¯­"},{"n":"ç²¤è¯­","v":"ç²¤è¯­"},{"n":"é—½å—è¯­","v":"é—½å—è¯­"},{"n":"éŸ©è¯­","v":"éŸ©è¯­"},{"n":"æ—¥è¯­","v":"æ—¥è¯­"},{"n":"å…¶å®ƒ","v":"å…¶å®ƒ"}]}],"zy":[{"key":"ç±»å‹","name":"ç±»å‹","value":[{"n":"å…¨éƒ¨","v":""},{"n":"çœŸäººç§€","v":"çœŸäººç§€"},{"n":"æ¸¸æˆ","v":"æ¸¸æˆ"},{"n":"ç«æŠ€","v":"ç«æŠ€"},{"n":"ç”µç«","v":"ç”µç«"},{"n":"æ¨ç†","v":"æ¨ç†"},{"n":"å½±è§†","v":"å½±è§†"},{"n":"è„±å£ç§€","v":"è„±å£ç§€"},{"n":"é€‰ç§€","v":"é€‰ç§€"},{"n":"æƒ…æ„Ÿ","v":"æƒ…æ„Ÿ"},{"n":"è®¿è°ˆ","v":"è®¿è°ˆ"},{"n":"æ’­æŠ¥","v":"æ’­æŠ¥"},{"n":"æ—…æ¸¸","v":"æ—…æ¸¸"},{"n":"éŸ³ä¹","v":"éŸ³ä¹"},{"n":"å–œå‰§","v":"å–œå‰§"},{"n":"ç¾é£Ÿ","v":"ç¾é£Ÿ"},{"n":"æ½®æµè¿åŠ¨","v":"æ½®æµè¿åŠ¨"},{"n":"äº²å­","v":"äº²å­"},{"n":"æ–‡åŒ–","v":"æ–‡åŒ–"},{"n":"äº’åŠ¨","v":"äº’åŠ¨"},{"n":"æ™šä¼š","v":"æ™šä¼š"},{"n":"èµ„è®¯","v":"èµ„è®¯"},{"n":"çºªå®","v":"çºªå®"},{"n":"æ›²è‰º","v":"æ›²è‰º"},{"n":"ç”Ÿæ´»","v":"ç”Ÿæ´»"},{"n":"èŒåœº","v":"èŒåœº"},{"n":"è´¢ç»","v":"è´¢ç»"},{"n":"æ±‚èŒ","v":"æ±‚èŒ"}]},{"key":"åœ°åŒº","name":"åœ°åŒº","value":[{"n":"å…¨éƒ¨","v":""},{"n":"å¤§é™†","v":"å¤§é™†"},{"n":"é¦™æ¸¯","v":"é¦™æ¸¯"},{"n":"å°æ¹¾","v":"å°æ¹¾"},{"n":"æ—¥æœ¬","v":"æ—¥æœ¬"},{"n":"éŸ©å›½","v":"éŸ©å›½"},{"n":"ç¾å›½","v":"ç¾å›½"}]},{"key":"å¹´ä»£","name":"å¹´ä»£","value":[{"n":"å…¨éƒ¨","v":""},{"n":"2025","v":"2025"},{"n":"2024","v":"2024"},{"n":"2023","v":"2023"},{"n":"2022","v":"2022"},{"n":"2021","v":"2021"},{"n":"2020","v":"2020"},{"n":"2019","v":"2019"},{"n":"2018","v":"2018"},{"n":"2017","v":"2017"},{"n":"2016","v":"2016"},{"n":"2015","v":"2015"},{"n":"2014","v":"2014"},{"n":"2013","v":"2013"},{"n":"2012","v":"2012"},{"n":"2011","v":"2011"},{"n":"2010","v":"2010"},{"n":"2009","v":"2009"},{"n":"2008","v":"2008"},{"n":"2007","v":"2007"},{"n":"2006","v":"2006"},{"n":"2005","v":"2005"},{"n":"2004","v":"2004"}]},{"key":"è¯­è¨€","name":"è¯­è¨€","value":[{"n":"å…¨éƒ¨","v":""},{"n":"å›½è¯­","v":"å›½è¯­"},{"n":"è‹±è¯­","v":"è‹±è¯­"},{"n":"ç²¤è¯­","v":"ç²¤è¯­"},{"n":"é—½å—è¯­","v":"é—½å—è¯­"},{"n":"éŸ©è¯­","v":"éŸ©è¯­"},{"n":"æ—¥è¯­","v":"æ—¥è¯­"},{"n":"å…¶å®ƒ","v":"å…¶å®ƒ"}]}]}}

        return result

    def homeVideoContent(self):
        videos = []

        try:
            detail = requests.get(url=xurl, headers=headerx)
            detail.encoding = "utf-8"
            res = detail.text
            doc = BeautifulSoup(res, "lxml")
            soups = doc.find_all('div', class_="vod-list")
            for soup in soups:
                vods = soup.find_all('div', class_="col-xs-4")
                for vod in vods:
                    names = vod.find('div', class_="vod-item")
                    name = names.find('h3').text
                    id = vod.select_one('h3 a')['href']
                    pics = vod.find_all('div')
                    pic = pics[1]['data-original']
                    if 'http' not in pic:
                        pic = xurl + pic
                    remarks = vod.find('span', class_="text-row-1")
                    remark = remarks.text.strip()
                    video = {
                        "vod_id": id,
                        "vod_name":  name,
                        "vod_pic": pic,
                        "vod_remarks":  remark
                             }
                    videos.append(video)
            result = {'list': videos}
            return result
        except:
            pass
    def categoryContent(self, cid, pg, filter, ext):
        result = {}
        videos = []
        if pg:
            page = int(pg)
        else:
            page = 1
        if 'ç±»å‹' in ext.keys():
            lxType = ext['ç±»å‹']
        else:
            lxType = ''
        if 'åœ°åŒº' in ext.keys():
            DqType = ext['åœ°åŒº']
        else:
            DqType = ''
        if 'è¯­è¨€' in ext.keys():
            YyType = ext['è¯­è¨€']
        else:
            YyType = ''
        if 'å¹´ä»£' in ext.keys():
            NdType = ext['å¹´ä»£']
        else:
            NdType = ''
        if 'å‰§æƒ…' in ext.keys():
            JqType = ext['å‰§æƒ…']
        else:
            JqType = ''
        if 'æ’åº' in ext.keys():
            pxType = ext['æ’åº']
        else:
            pxType = ''
            url = f'{xurl}/vod/{cid}-{DqType}--{lxType}-{YyType}----{pg}---{NdType}/'
                    # https://cupfoxys.cc/vod/dsj-%E5%A4%A7%E9%99%86--%E7%88%B1%E6%83%85-%E5%9B%BD%E8%AF%AD-------2024/
        try:
            print(url)
            detail = requests.get(url=url, headers=headerx)
            detail.encoding = "utf-8"
            res = detail.text
            doc = BeautifulSoup(res, "lxml")
            soups = doc.find_all('div', class_="row")
            for soup in soups:
                vods = soup.find_all('div', class_="col-xs-4")
                for vod in vods:
                    names = vod.find('div', class_="vod-item")
                    name = names.find('h3').text
                    id = vod.select_one('h3 a')['href']
                    pics = vod.find_all('div')
                    pic = pics[1]['data-original']
                    if 'http' not in pic:
                        pic = xurl + pic
                    remarks = vod.find('span', class_="text-row-1")
                    remark = remarks.text.strip()
                    video = {
                        "vod_id": id,
                        "vod_name": name,
                        "vod_pic": pic,
                        "vod_remarks":  remark
                            }
                    videos.append(video)
        except:
            pass
        result = {'list': videos}
        result['page'] = pg
        result['pagecount'] = 9999
        result['limit'] = 90
        result['total'] = 999999
        return result
    def detailContent(self, ids):
        global pm
        did = ids[0]
        result = {}
        videos = []
        if 'http' not in did:
            did = xurl + did
        res = requests.get(url=did, headers=headerx)
        res.encoding = "utf-8"
        res = res.text
        tiaozhuan = '0'
        if tiaozhuan == '1':
            didt = self.extract_middle_text(res, 'class="play">', '</p>', 1, 'href="(.*?)"')
            if 'http' not in didt:
                didt = xurl + didt
                ress = requests.get(url=didt, headers=headerx)
                ress.encoding = "utf-8"
                ress = ress.text
        duoxian = '0'
        if duoxian == '1':
            doc = BeautifulSoup(ress, 'lxml')
            soups = doc.find('span', class_='animate__animated')
            vods = soups.find_all('a')[1:]
            res1 = ''
            for vod in vods:
                url = self.extract_middle_text(str(vod), 'href="', '"', 0)
                if 'http' not in url:
                    url = xurl + url
                    resss = requests.get(url, headers=headerx)
                    resss.encoding = 'utf-8'
                    resss = resss.text
                    res1 = res1 + resss
            res2 = ress + res1
        url = 'https://9071.kstore.vip/py/yz.txt'
        response = requests.get(url)
        response.encoding = 'utf-8'
        code = response.text
        name = self.extract_middle_text(code, "s1='", "'", 0)
        Jumps = self.extract_middle_text(code, "s2='", "'", 0)
        content = 'ğŸ˜¸ç¹åğŸ‰ç»å‰§æƒ…ğŸ“¢æœ¬èµ„æºæ¥æºäºç½‘ç»œğŸš“ä¾µæƒè¯·è”ç³»åˆ é™¤ğŸ‘‰' + self.extract_middle_text(res,'<p class="detail-intro-text','</p>', 0)
        content = content.replace('text-row ewave-collapse-content">', '').replace('\u3000\u3000', '')
        if name not in content:
            bofang = Jumps
        else:
            bofang = self.extract_middle_text(res, '<ul class="row ewave-tab-content', '</ul>', 3, 'href="(.*?)">(.*?)</a></li>')
        xianlu = self.extract_middle_text(res, 'ul class="tab-box','</ul>',2, '<a href=".*?">(.*?)</a>')
        actors = self.extract_middle_text(res, 'class="fa fa-user-o fa-fw"></i><span>ä¸»æ¼”ï¼š', '</li>', 1,'href=".*?" target=".*?">(.*?)</a>')
        director = self.extract_middle_text(res, 'class="fa fa-user-o fa-fw"></i><span>å¯¼æ¼”ï¼š', '</li>', 1,'<a href=".*?" target=".*?">(.*?)</a>')
        videos.append({
            "vod_id": did,
            "vod_actor": actors,
            "vod_director": director,
            "vod_content": content,
            "vod_play_from": xianlu,
            "vod_play_url": bofang
                     })
        result['list'] = videos
        return result
    def playerContent(self, flag, id, vipFlags):
        parts = id.split("http")
        xiutan = 0
        if xiutan == 0:
            if len(parts) > 1:
                before_https, after_https = parts[0], 'http' + parts[1]
            if '239755956819.mp4' in after_https:
                url = after_https
            else:
                res = requests.get(url=after_https, headers=headerx)
                res = res.text
                url = self.extract_middle_text(res, '},"url":"', '"', 0).replace('\\', '')
            result = {}
            result["parse"] = xiutan
            result["playUrl"] = ''
            result["url"] = url
            result["header"] = headerx
            return result
        if xiutan == 1:
            if len(parts) > 1:
                before_https, after_https = parts[0], 'http' + parts[1]
            result = {}
            result["parse"] = xiutan
            result["playUrl"] = ''
            result["url"] = after_https
            result["header"] = headerx
            return result
    def searchContentPage(self, key, quick, page):
        result = {}
        videos = []
        if not page:
            page = '1'
        if page == '1':
            url = f'{xurl}/search/-------------/?wd={key}'
        else:
            url = f'{xurl}/search/{key}----------{str(page)}---/'
        detail = requests.get(url=url, headers=headerx)
        detail.encoding = "utf-8"
        res = detail.text
        doc = BeautifulSoup(res, "lxml")
        soups = doc.find_all('div', class_="search-list")
        for soup in soups:
            vods = soup.find_all('div', class_="search-item row")
            for vod in vods:
                names = vod.find('h2', class_="search-item-title")
                name = names.find('a')['title']
                id = vod.find('a')['href']
                pic = vod.select_one('a div')['data-original']
                if 'http' not in pic:
                    pic = xurl + pic
                remarks = vod.find('ul', class_="search-item-desc")
                remark = remarks.find('li').text
                video = {
                    "vod_id": id,
                    "vod_name": name,
                    "vod_pic": pic,
                    "vod_remarks": remark
                        }
                videos.append(video)
        result['list'] = videos
        result['page'] = page
        result['pagecount'] = 9999
        result['limit'] = 90
        result['total'] = 999999
        return result
    def searchContent(self, key, quick, pg="1"):
        return self.searchContentPage(key, quick, '1')
    def localProxy(self, params):
        if params['type'] == "m3u8":
            return self.proxyM3u8(params)
        elif params['type'] == "media":
            return self.proxyMedia(params)
        elif params['type'] == "ts":
            return self.proxyTs(params)
        return None



